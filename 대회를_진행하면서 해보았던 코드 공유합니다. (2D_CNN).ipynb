{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"voice_2D_CNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyO9GQlRqZn+rbeVnogEeXYi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsrkB6B_le_N","executionInfo":{"status":"ok","timestamp":1624522367427,"user_tz":-540,"elapsed":217,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"16336120-3d49-4613-b544-bc4f629f4f5f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qmspRt65lgZm"},"source":["import keras\n","from keras import regularizers\n","from keras.preprocessing import sequence\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential, Model, model_from_json\n","from keras.layers import Dense, Embedding, LSTM\n","from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n","from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n","from keras.utils.np_utils import to_categorical\n","from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n","                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n","from keras import losses, models, optimizers\n","from keras.activations import relu, softmax\n","from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout,\n","                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\n","\n","# sklearn\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Other  \n","from tqdm import tqdm, tqdm_pandas\n","import scipy\n","from scipy.stats import skew\n","import librosa\n","import librosa.display\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from matplotlib.pyplot import specgram\n","import pandas as pd\n","import seaborn as sns\n","import glob \n","import os\n","import sys\n","import IPython.display as ipd  # To play sound in the notebook\n","import warnings\n","# ignore warnings \n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufPGFNf7hQnN"},"source":["class AudioTransform:\n","    def __init__(self, always_apply=False, p=0.5):\n","        self.always_apply = always_apply\n","        self.p = p\n","\n","    def __call__(self, y: np.ndarray):\n","        if self.always_apply:\n","            return self.apply(y)\n","        else:\n","            if np.random.rand() < self.p:\n","                return self.apply(y)\n","            else:\n","                return y\n","\n","    def apply(self, y: np.ndarray):\n","        raise NotImplementedError\n","\n","\n","class Compose:\n","    def __init__(self, transforms: list):\n","        self.transforms = transforms\n","\n","    def __call__(self, y: np.ndarray):\n","        for trns in self.transforms:\n","            y = trns(y)\n","        return y\n","\n","\n","class OneOf:\n","    def __init__(self, transforms: list):\n","        self.transforms = transforms\n","\n","    def __call__(self, y: np.ndarray):\n","        n_trns = len(self.transforms)\n","        trns_idx = np.random.choice(n_trns)\n","        trns = self.transforms[trns_idx]\n","        return trns(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iacW288bhQkq"},"source":["class PitchShift(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_steps=5, sr=32000):\n","        super().__init__(always_apply, p)\n","\n","        self.max_steps = max_steps\n","        self.sr = sr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        n_steps = np.random.randint(-self.max_steps, self.max_steps)\n","        augmented = librosa.effects.pitch_shift(y, sr=self.sr, n_steps=n_steps)\n","        return augmented\n","\n","class VolumeControl(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, db_limit=10, mode=\"uniform\"):\n","        super().__init__(always_apply, p)\n","\n","        assert mode in [\"uniform\", \"fade\", \"fade\", \"cosine\", \"sine\"], \\\n","            \"`mode` must be one of 'uniform', 'fade', 'cosine', 'sine'\"\n","\n","        self.db_limit= db_limit\n","        self.mode = mode\n","\n","    def apply(self, y: np.ndarray, **params):\n","        db = np.random.uniform(-self.db_limit, self.db_limit)\n","        if self.mode == \"uniform\":\n","            db_translated = 10 ** (db / 20)\n","        elif self.mode == \"fade\":\n","            lin = np.arange(len(y))[::-1] / (len(y) - 1)\n","            db_translated = 10 ** (db * lin / 20)\n","        elif self.mode == \"cosine\":\n","            cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n","            db_translated = 10 ** (db * cosine / 20)\n","        else:\n","            sine = np.sin(np.arange(len(y)) / len(y) * np.pi * 2)\n","            db_translated = 10 ** (db * sine / 20)\n","        augmented = y * db_translated\n","        return augmented\n","\n","class TimeShift(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_shift_second=2, sr=32000, padding_mode=\"replace\"):\n","        super().__init__(always_apply, p)\n","    \n","        assert padding_mode in [\"replace\", \"zero\"], \"`padding_mode` must be either 'replace' or 'zero'\"\n","        self.max_shift_second = max_shift_second\n","        self.sr = sr\n","        self.padding_mode = padding_mode\n","\n","    def apply(self, y: np.ndarray, **params):\n","        shift = np.random.randint(-self.sr * self.max_shift_second, self.sr * self.max_shift_second)\n","        augmented = np.roll(y, shift)\n","        if self.padding_mode == \"zero\":\n","            if shift > 0:\n","                augmented[:shift] = 0\n","            else:\n","                augmented[shift:] = 0\n","        return augmented\n","\n","class TimeStretch(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_rate=1.2):\n","        super().__init__(always_apply, p)\n","\n","        self.max_rate = max_rate\n","\n","    def apply(self, y: np.ndarray, **params):\n","        rate = np.random.uniform(0, self.max_rate)\n","        augmented = librosa.effects.time_stretch(y, rate)\n","        return augmented\n","\n","class PitchShift(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_steps=5, sr=32000):\n","        super().__init__(always_apply, p)\n","\n","        self.max_steps = max_steps\n","        self.sr = sr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        n_steps = np.random.randint(-self.max_steps, self.max_steps)\n","        augmented = librosa.effects.pitch_shift(y, sr=self.sr, n_steps=n_steps)\n","        return augmented    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKGO7hcnlq_1"},"source":["def speedNpitch(data):\n","    \"\"\"\n","    속도와 피쳐 튜닝\n","    \"\"\"\n","    # you can change low and high here\n","    length_change = np.random.uniform(low=0.8, high = 1)\n","    speed_fac = 1.2  / length_change # try changing 1.0 to 2.0 ... =D\n","    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n","    minlen = min(data.shape[0], tmp.shape[0])\n","    data *= 0\n","    data[0:minlen] = tmp[0:minlen]\n","    return data\n","\n","'''\n","메트릭스로 추출\n","'''\n","def prepare_data(df, n, aug, mfcc):\n","    X = np.empty(shape=(df.shape[0], n, 216, 1))\n","    input_length = sampling_rate * audio_duration\n","    \n","    cnt = 0\n","    for fname in tqdm(df.id):\n","        file_path = '/content/drive/MyDrive/voice/all/'+fname\n","        data, _ = librosa.load(file_path, sr=sampling_rate\n","                               ,res_type=\"kaiser_fast\"\n","                               ,duration=2.5\n","                               ,offset=0.5\n","                              )\n","        transform = Compose([\n","        PitchShift(max_steps=2, sr=_),\n","        TimeStretch(),\n","        TimeShift(sr=_)\n","        ])\n","        y_composed = transform(data)\n","        _ = np.array(y_composed)\n","        # Random offset / Padding\n","        if len(data) > input_length:\n","            max_offset = len(data) - input_length\n","            offset = np.random.randint(max_offset)\n","            data = data[offset:(input_length+offset)]\n","        else:\n","            if input_length > len(data):\n","                max_offset = input_length - len(data)\n","                offset = np.random.randint(max_offset)\n","            else:\n","                offset = 0\n","            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n","\n","        # Augmentation? \n","        if aug == 1:\n","            data = speedNpitch(data)\n","        \n","        # which feature?\n","        if mfcc == 1:\n","            # MFCC extraction \n","            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n","            MFCC = np.expand_dims(MFCC, axis=-1)\n","            X[cnt,] = MFCC\n","            \n","        else:\n","            # Log-melspectogram\n","            melspec = librosa.feature.melspectrogram(data, n_mels = n_melspec)   \n","            logspec = librosa.amplitude_to_db(melspec)\n","            logspec = np.expand_dims(logspec, axis=-1)\n","            X[cnt,] = logspec\n","            \n","        cnt += 1\n","    \n","    return X\n","\n"," \n","    \n","'''\n","# 2D CNN model \n","'''\n","def get_2d_conv_model(n):\n","    nclass = 6\n","    inp = Input(shape=(n,216,1))  #2D matrix of 30 MFCC bands by 216 audio length.\n","    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    x = MaxPool2D()(x)\n","    x = Dropout(rate=0.2)(x)\n","    \n","    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    x = MaxPool2D()(x)\n","    x = Dropout(rate=0.2)(x)\n","    \n","    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    x = MaxPool2D()(x)\n","    x = Dropout(rate=0.2)(x)\n","    \n","    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    x = MaxPool2D()(x)\n","    x = Dropout(rate=0.2)(x)\n","    \n","    x = Flatten()(x)\n","    x = Dense(64)(x)\n","    x = Dropout(rate=0.2)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    x = Dropout(rate=0.2)(x)\n","    \n","    out = Dense(nclass, activation=softmax)(x)\n","    model = models.Model(inputs=inp, outputs=out)\n","    \n","    opt = optimizers.Adam(0.001)\n","    model.compile(optimizer=opt, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['acc'])\n","    return model\n","\n","\n","class get_results:\n","\n","    \n","    def __init__(self, model_history, model ,X_test, y_test, labels):\n","        self.model_history = model_history\n","        self.model = model\n","        self.X_test = X_test\n","        self.y_test = y_test             \n","        self.labels = labels\n","\n","    def create_plot(self, model_history):\n","        '''Check the logloss of both train and validation, make sure they are close and have plateau'''\n","        plt.plot(model_history.history['loss'])\n","        plt.plot(model_history.history['val_loss'])\n","        plt.title('model loss')\n","        plt.ylabel('loss')\n","        plt.xlabel('epoch')\n","        plt.legend(['train', 'test'], loc='upper left')\n","        plt.show()\n","\n","    def create_results(self, model):\n","        '''predict on test set and get accuracy results'''\n","        opt = optimizers.Adam(0.001)\n","        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","        score = model.evaluate(X_test, y_test, verbose=0)\n","        print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n","\n","    def confusion_results(self, X_test, y_test, labels, model):\n","        '''plot confusion matrix results'''\n","        preds = model.predict(X_test, \n","                                 batch_size=16, \n","                                 verbose=2)\n","        preds=preds.argmax(axis=1)\n","        preds = preds.astype(int).flatten()\n","        preds = (lb.inverse_transform((preds)))\n","\n","        actual = y_test.argmax(axis=1)\n","        actual = actual.astype(int).flatten()\n","        actual = (lb.inverse_transform((actual)))\n","\n","        classes = labels\n","        classes.sort()    \n","\n","        c = confusion_matrix(actual, preds)\n","        print_confusion_matrix(c, class_names = classes)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3KO7NYtsArz"},"source":["path = '/content/drive/MyDrive/voice/'\n","train = pd.read_csv(path + 'train.csv')\n","sample_submission = pd.read_csv(path + 'sample_submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGOChAHWslJq","outputId":"0e74fa50-623c-453b-e6bd-074cbeff2eb3"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_mfcc = 30\n","mfcc_test = prepare_data(train, n = n_mfcc, aug = 0, mfcc = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 24/25520 [00:11<3:36:44,  1.96it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"d_IqSwcBr5VF"},"source":["accent_map = {}\n","for i, loc in enumerate(train['accent'].unique()):\n","    accent_map[loc] = i"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wlX5_rya6TN","executionInfo":{"status":"ok","timestamp":1624522375643,"user_tz":-540,"elapsed":3,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"113428c4-4e23-4387-ffdb-98d455f3a7a2"},"source":["accent_map"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Africa': 0,\n"," 'Australia': 1,\n"," 'Canada': 2,\n"," 'England': 3,\n"," 'Hongkong': 4,\n"," 'US': 5}"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"rYqvwnSksUs4"},"source":["train['accent'] = train['accent'].map(accent_map)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"POoLKfXrspRK"},"source":["X_train, X_test, y_train, y_test = train_test_split(mfcc\n","                                                    , train.accent\n","                                                    , test_size=0.25\n","                                                    , shuffle=True\n","                                                    , random_state=42\n","                                                   )\n","\n","\n","#one hot encode the target \n","#lb = LabelEncoder()\n","#y_train = lb.fit_transform(y_train)\n","#y_test = lb.fit_transform(y_test)\n","\n","# Normalization as per the standard NN process\n","mean = np.mean(X_train, axis=0)\n","std = np.std(X_train, axis=0)\n","\n","X_train = (X_train - mean)/std\n","X_test = (X_test - mean)/std\n","\n","# Build CNN model \n","model = get_2d_conv_model(n=n_mfcc)\n","model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n","                    batch_size=16, verbose = 2, epochs=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEAB0cH79JHo"},"source":["def prepare_data_test(df, n, aug, mfcc):\n","    X_test = np.empty(shape=(df.shape[0], n, 216, 1))\n","    input_length = sampling_rate * audio_duration\n","    \n","    cnt = 0\n","    for fname in tqdm(df.path):\n","        file_path = fname\n","        data, _ = librosa.load(file_path, sr=sampling_rate\n","                               ,res_type=\"kaiser_fast\"\n","                               ,duration=2.5\n","                               ,offset=0.5\n","                              )\n","        transform = Compose([\n","        PitchShift(max_steps=2, sr=_),\n","        TimeStretch(),\n","        TimeShift(sr=_)\n","        ])\n","        y_composed = transform(data)\n","        _ = np.array(y_composed)\n","        # Random offset / Padding\n","        if len(data) > input_length:\n","            max_offset = len(data) - input_length\n","            offset = np.random.randint(max_offset)\n","            data = data[offset:(input_length+offset)]\n","        else:\n","            if input_length > len(data):\n","                max_offset = input_length - len(data)\n","                offset = np.random.randint(max_offset)\n","            else:\n","                offset = 0\n","            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n","\n","        # Augmentation? \n","        if aug == 1:\n","            data = speedNpitch(data)\n","        \n","        # which feature?\n","        if mfcc == 1:\n","            # MFCC extraction \n","            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n","            MFCC = np.expand_dims(MFCC, axis=-1)\n","            X_test[cnt,] = MFCC\n","            \n","        else:\n","            # Log-melspectogram\n","            melspec = librosa.feature.melspectrogram(data, n_mels = n_melspec)   \n","            logspec = librosa.amplitude_to_db(melspec)\n","            logspec = np.expand_dims(logspec, axis=-1)\n","            X_test[cnt,] = logspec\n","            \n","        cnt += 1\n","    \n","    return X_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"WYrewoNdAIUv","executionInfo":{"status":"ok","timestamp":1624544039999,"user_tz":-540,"elapsed":16,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"9ffe7a8c-4b19-4926-f6f9-06c399647b90"},"source":["\"\"\"\n","def get_id(data):\n","    return np.int(data.split(\"/\")[-1].split(\".\")[-2])\n","\n","test_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\n","test_[\"path\"] = glob(\"/content/drive/MyDrive/voice/test/*.wav\")\n","test_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\n","\n","test_.head()\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ndef get_id(data):\\n    return np.int(data.split(\"/\")[-1].split(\".\")[-2])\\n\\ntest_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\\ntest_[\"path\"] = glob(\"/content/drive/MyDrive/voice/test/*.wav\")\\ntest_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\\n\\ntest_.head()\\n'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"sA9V3DYFBCJ2"},"source":["#test_.to_csv(path+\"test_.csv\", index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atXjnDv4AvOw"},"source":["test = pd.read_csv(path + 'test_.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OasjUEeIb2y6"},"source":["test = test.sort_values(by=['id'], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M-mGqBfm-5xI"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_mfcc = 30\n","mfcc_test = prepare_data_test(test, n = n_mfcc, aug = 0, mfcc = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-cd5GO2XoOu"},"source":["prediction = model.predict(mfcc_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6pnpaSJMDpI"},"source":["predict = pd.DataFrame(prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfV6xmFQa9wL"},"source":["accent_map"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pu_2-L2ueQN_"},"source":["sample_submission.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Q-xeE5gazTJ"},"source":["sample_submission['africa'] = predict[0]\n","sample_submission['australia'] = predict[1]\n","sample_submission['canada'] = predict[2]\n","sample_submission['england'] = predict[3]\n","sample_submission['hongkong'] = predict[4]\n","sample_submission['us'] = predict[5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGGEJDIxeZ_b"},"source":["sample_submission.to_csv(data_path+'2d_cnn.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqnGr0Ew0ZA3"},"source":["results = get_results(model_history,model,X_test,y_test, train.accent.unique())\n","results.create_plot(model_history)\n","results.create_results(model)\n","results.confusion_results(X_test, y_test, train.accent.unique(), model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PkPOuhVks9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624538731318,"user_tz":-540,"elapsed":16339310,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"64bd2e7e-578d-4b53-89e4-6d71af7c13bb"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_mfcc = 30\n","mfcc_aug = prepare_data(train, n = n_mfcc, aug = 1, mfcc = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 25520/25520 [4:32:19<00:00,  1.56it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Ba3IDQe5px4J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624544039996,"user_tz":-540,"elapsed":2624233,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"f06c66df-d41f-4f35-8f4a-792ac228669e"},"source":["X_train, X_test, y_train, y_test = train_test_split(mfcc_aug\n","                                                    , train.accent\n","                                                    , test_size=0.25\n","                                                    , shuffle=True\n","                                                    , random_state=42\n","                                                   )\n","\n","# one hot encode the target \n","#lb = LabelEncoder()\n","#y_train = to_categorical(lb.fit_transform(y_train))\n","#y_test = to_categorical(lb.fit_transform(y_test))\n","\n","# Normalization as per the standard NN process\n","# mean = np.mean(X_train, axis=0)\n","# std = np.std(X_train, axis=0)\n","\n","# X_train = (X_train - mean)/std\n","# X_test = (X_test - mean)/std\n","\n","# Build CNN model \n","model = get_2d_conv_model(n=n_mfcc)\n","model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n","                    batch_size=64, verbose = 2, epochs=30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","300/300 - 122s - loss: 1.4920 - acc: 0.4030 - val_loss: 1.4535 - val_acc: 0.4282\n","Epoch 2/30\n","300/300 - 87s - loss: 1.2910 - acc: 0.4882 - val_loss: 1.3463 - val_acc: 0.4900\n","Epoch 3/30\n","300/300 - 87s - loss: 1.2221 - acc: 0.5250 - val_loss: 1.2564 - val_acc: 0.5219\n","Epoch 4/30\n","300/300 - 89s - loss: 1.1766 - acc: 0.5542 - val_loss: 1.2609 - val_acc: 0.4680\n","Epoch 5/30\n","300/300 - 92s - loss: 1.1286 - acc: 0.5752 - val_loss: 1.2411 - val_acc: 0.5105\n","Epoch 6/30\n","300/300 - 86s - loss: 1.0911 - acc: 0.5923 - val_loss: 1.2052 - val_acc: 0.5161\n","Epoch 7/30\n","300/300 - 87s - loss: 1.0521 - acc: 0.6029 - val_loss: 1.1797 - val_acc: 0.5398\n","Epoch 8/30\n","300/300 - 88s - loss: 1.0181 - acc: 0.6166 - val_loss: 1.1004 - val_acc: 0.5839\n","Epoch 9/30\n","300/300 - 90s - loss: 1.0009 - acc: 0.6216 - val_loss: 1.1148 - val_acc: 0.5828\n","Epoch 10/30\n","300/300 - 96s - loss: 0.9676 - acc: 0.6379 - val_loss: 1.0987 - val_acc: 0.5751\n","Epoch 11/30\n","300/300 - 87s - loss: 0.9420 - acc: 0.6421 - val_loss: 1.0780 - val_acc: 0.5755\n","Epoch 12/30\n","300/300 - 87s - loss: 0.9211 - acc: 0.6518 - val_loss: 1.0233 - val_acc: 0.6155\n","Epoch 13/30\n","300/300 - 86s - loss: 0.9066 - acc: 0.6559 - val_loss: 0.9819 - val_acc: 0.6235\n","Epoch 14/30\n","300/300 - 87s - loss: 0.8894 - acc: 0.6611 - val_loss: 1.0281 - val_acc: 0.5970\n","Epoch 15/30\n","300/300 - 87s - loss: 0.8574 - acc: 0.6771 - val_loss: 0.9640 - val_acc: 0.6274\n","Epoch 16/30\n","300/300 - 85s - loss: 0.8489 - acc: 0.6815 - val_loss: 0.9952 - val_acc: 0.6312\n","Epoch 17/30\n","300/300 - 87s - loss: 0.8306 - acc: 0.6839 - val_loss: 0.9126 - val_acc: 0.6516\n","Epoch 18/30\n","300/300 - 83s - loss: 0.8078 - acc: 0.6945 - val_loss: 0.9083 - val_acc: 0.6472\n","Epoch 19/30\n","300/300 - 85s - loss: 0.7937 - acc: 0.7018 - val_loss: 0.8927 - val_acc: 0.6658\n","Epoch 20/30\n","300/300 - 84s - loss: 0.7923 - acc: 0.7004 - val_loss: 0.9155 - val_acc: 0.6429\n","Epoch 21/30\n","300/300 - 84s - loss: 0.7698 - acc: 0.7093 - val_loss: 1.0439 - val_acc: 0.5868\n","Epoch 22/30\n","300/300 - 84s - loss: 0.7585 - acc: 0.7133 - val_loss: 0.8948 - val_acc: 0.6586\n","Epoch 23/30\n","300/300 - 84s - loss: 0.7521 - acc: 0.7135 - val_loss: 0.8943 - val_acc: 0.6614\n","Epoch 24/30\n","300/300 - 84s - loss: 0.7355 - acc: 0.7224 - val_loss: 0.9214 - val_acc: 0.6497\n","Epoch 25/30\n","300/300 - 82s - loss: 0.7555 - acc: 0.7167 - val_loss: 0.8747 - val_acc: 0.6633\n","Epoch 26/30\n","300/300 - 83s - loss: 0.7129 - acc: 0.7312 - val_loss: 0.9104 - val_acc: 0.6561\n","Epoch 27/30\n","300/300 - 82s - loss: 0.7064 - acc: 0.7331 - val_loss: 0.8482 - val_acc: 0.6846\n","Epoch 28/30\n","300/300 - 84s - loss: 0.6960 - acc: 0.7353 - val_loss: 0.8739 - val_acc: 0.6705\n","Epoch 29/30\n","300/300 - 84s - loss: 0.6769 - acc: 0.7443 - val_loss: 0.8724 - val_acc: 0.6792\n","Epoch 30/30\n","300/300 - 89s - loss: 0.6866 - acc: 0.7406 - val_loss: 0.8586 - val_acc: 0.6726\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnVMxKkLt8P6","executionInfo":{"status":"ok","timestamp":1624547577458,"user_tz":-540,"elapsed":3537472,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"3d19ddeb-3800-461c-a5dd-5a404ccd2c82"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_mfcc = 30\n","mfcc_aug_test = prepare_data_test(test, n = n_mfcc, aug = 1, mfcc = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 6100/6100 [58:57<00:00,  1.72it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Lfmly2wCt8NT"},"source":["prediction = model.predict(mfcc_aug_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKOMhOOAt8Ka"},"source":["predict = pd.DataFrame(prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wSrwFl8uozZ"},"source":["sample_submission['africa'] = predict[0]\n","sample_submission['australia'] = predict[1]\n","sample_submission['canada'] = predict[2]\n","sample_submission['england'] = predict[3]\n","sample_submission['hongkong'] = predict[4]\n","sample_submission['us'] = predict[5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMoSls-kumYr"},"source":["sample_submission.to_csv(path+'2d_cnn_aug.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9KQ3XdbBpxvx"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_melspec = 60\n","specgram = prepare_data(train, n = n_melspec, aug = 0, mfcc = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FP7Uvhuip6ai"},"source":["X_train, X_test, y_train, y_test = train_test_split(specgram\n","                                                    , train.accent\n","                                                    , test_size=0.25\n","                                                    , shuffle=True\n","                                                    , random_state=42\n","                                                   )\n","\n","\n","\n","# one hot encode the target \n","lb = LabelEncoder()\n","y_train = to_categorical(lb.fit_transform(y_train))\n","y_test = to_categorical(lb.fit_transform(y_test))\n","\n","# Normalization as per the standard NN process\n","mean = np.mean(X_train, axis=0)\n","std = np.std(X_train, axis=0)\n","\n","X_train = (X_train - mean)/std\n","X_test = (X_test - mean)/std\n","\n","# Build CNN model \n","model = get_2d_conv_model(n=n_melspec)\n","model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n","                    batch_size=16, verbose = 2, epochs=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1k_je12sJuHd"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_melspec = 60\n","specgram = prepare_data_test(test, n = n_melspec, aug = 0, mfcc = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsU2-OutJ1p8"},"source":["prediction = model.predict(specgram)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eoeCYOyqJ1np"},"source":["predict = pd.DataFrame(prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ee1ysC0lJ1lf"},"source":["sample_submission['africa'] = predict[0]\n","sample_submission['australia'] = predict[1]\n","sample_submission['canada'] = predict[2]\n","sample_submission['england'] = predict[3]\n","sample_submission['hongkong'] = predict[4]\n","sample_submission['us'] = predict[5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8METTAxJ1iz"},"source":["sample_submission.to_csv(data_path+'2d_cnn_spac.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ekiyfr6Fp6VR"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_melspec = 60\n","aug_specgram = prepare_data(train,  n = n_melspec, aug = 1, mfcc = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tBgyo7-HqC4Q"},"source":["X_train, X_test, y_train, y_test = train_test_split(aug_specgram\n","                                                    , train.accent\n","                                                    , test_size=0.25\n","                                                    , shuffle=True\n","                                                    , random_state=42\n","                                                   )\n","\n","\n","\n","# one hot encode the target \n","lb = LabelEncoder()\n","y_train = to_categorical(lb.fit_transform(y_train))\n","y_test = to_categorical(lb.fit_transform(y_test))\n","\n","# Normalization as per the standard NN process\n","mean = np.mean(X_train, axis=0)\n","std = np.std(X_train, axis=0)\n","\n","X_train = (X_train - mean)/std\n","X_test = (X_test - mean)/std\n","\n","# Build CNN model \n","model = get_2d_conv_model(n=n_melspec)\n","model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n","                    batch_size=16, verbose = 2, epochs=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4P7y-xgmfZp9"},"source":["sampling_rate=44100\n","audio_duration=2.5\n","n_melspec = 60\n","aug_specgram = prepare_data_test(test,  n = n_melspec, aug = 1, mfcc = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Fgt2oOaKLdO"},"source":["prediction = model.predict(aug_specgram)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0c0piWqcKN_o"},"source":["predict = pd.DataFrame(prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSH51kHvKRdY"},"source":["sample_submission['africa'] = predict[0]\n","sample_submission['australia'] = predict[1]\n","sample_submission['canada'] = predict[2]\n","sample_submission['england'] = predict[3]\n","sample_submission['hongkong'] = predict[4]\n","sample_submission['us'] = predict[5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3POnYdtzKSto"},"source":["sample_submission.to_csv(data_path+'2d_cnn_spac_aug.csv', index=False)"],"execution_count":null,"outputs":[]}]}